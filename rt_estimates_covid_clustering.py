# -*- coding: utf-8 -*-
"""rt-estimates-covid_clustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k1rSuHUb1L0ADU1JpTEY7KVPQnSjLLn4
"""



import pandas as pd
import glob
import os
from tsfresh import extract_features
from tsfresh.feature_extraction import EfficientFCParameters
import numpy as np
from google.colab import drive
drive.mount('/content/drive')


input_path = "/content/drive/MyDrive/rt-estimates-covid/rt_results/rt_*.csv"
output_path = "/content/drive/MyDrive/rt-estimates-covid/rt_results/country_features_smoothed.csv"

print(f"Looking for files in: {input_path}")
all_files = glob.glob(input_path)
print(f"Found {len(all_files)} country files.")


df_list = []

for filename in all_files:
    try:
        df = pd.read_csv(filename)


        base_name = os.path.basename(filename)
        country_name = base_name.replace("rt_", "").replace(".csv", "").replace("_", " ")
        df['Country'] = country_name

        if 'mean' in df.columns and 'date' in df.columns:
            df = df[['date', 'Country', 'mean']]
            df_list.append(df)

    except Exception as e:
        print(f"Skipping {filename}: {e}")

if not df_list:
    raise ValueError("No valid data found! Double check the folder path.")

full_df = pd.concat(df_list, ignore_index=True)


full_df['date'] = pd.to_datetime(full_df['date'], errors='coerce')
full_df = full_df.dropna(subset=['date', 'Country', 'mean'])


full_df['mean'] = full_df['mean'].replace([np.inf, -np.inf], np.nan)
full_df['mean'] = full_df['mean'].fillna(0)
print("Data loaded and cleaned. Starting feature extraction...")

def run_feature_extraction():
    try:
        extracted_features = extract_features(
            full_df,
            column_id="Country",
            column_sort="date",
            default_fc_parameters=EfficientFCParameters(),
            n_jobs=1
        )

        extracted_features = extracted_features.dropna(axis=1, how='all')
        extracted_features = extracted_features.fillna(0)

        extracted_features.to_csv(output_path)
        print(f"Success! Saved features to: {output_path}")

    except Exception as e:
        print(f"Feature extraction failed: {e}")

run_feature_extraction()

"""Now that `full_df` is globally defined, you can re-run cell `T4pXTj4MrlTw` to generate 'The Three Types of Pandemic Trajectories' plot, which visualizes the Rt trajectory for each cluster."""



extracted_features = pd.read_csv('/content/drive/MyDrive/rt-estimates-covid/rt_results/country_features_smoothed.csv', index_col=0)

features_clean = impute(extracted_features)

full_df['mean'] = full_df['mean'].replace([np.inf, -np.inf], np.nan)
full_df['mean'] = full_df['mean'].fillna(0)
features_clean = features_clean.replace([np.inf, -np.inf], np.nan)
features_clean = features_clean.fillna(0)


std_devs = features_clean.std()
features_clean = features_clean.loc[:, (std_devs != 0) & (np.isfinite(std_devs))]


selected_countries = ['Italy', 'Spain', 'United Kingdom',, 'France', 'Poland', 'Mexico', 'Brazil', 'South Africa', 'Colombia', 'United States']
features_filtered = features_clean[features_clean.index.isin(selected_countries)]

scaler = StandardScaler()
features_scaled = scaler.fit_transform(features_filtered)

pca = PCA(n_components=2)
pca_result = pca.fit_transform(features_scaled)

kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
clusters = kmeans.fit_predict(features_scaled)


plt.figure(figsize=(12, 8))
sns.scatterplot(
    x=pca_result[:, 0],
    y=pca_result[:, 1],
    hue=clusters,
    palette='viridis',
    s=100,
    style=clusters
)


for i, country in enumerate(features_filtered.index):
    plt.text(pca_result[i, 0]+1.8, pca_result[i, 1], country, fontsize=11, ha='left')

plt.title('The Pandemic Map: Grouping Countries by Rt Trajectory (Selected Countries)', fontsize=16)
plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]*100:.2f}% Variance)')
plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]*100:.2f}% Variance)')
plt.legend(title='Cluster')
plt.grid(True, alpha=0.3)
plt.show()

country_clusters_df = pd.DataFrame({
    'Country': features_clean.index,
    'Cluster': clusters
})

output_cluster_path = '/content/drive/MyDrive/rt-estimates-covid/rt_results/country_clusters.csv'

country_clusters_df.to_csv(output_cluster_path, index=False)

print(f"Predicted clusters saved to: {output_cluster_path}")
display(country_clusters_df.head())

from sklearn.cluster import KMeans

wcss = []

for k in range(1, 12):
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(features_scaled)
    wcss.append(kmeans.inertia_)

print("WCSS values for k=1 to 10:", wcss)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(range(1, 12), wcss, marker='o', linestyle='--')
plt.title('Elbow Method for Optimal K')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Within-Cluster Sum of Squares (WCSS)')
plt.xticks(range(1, 12))
plt.grid(True)
plt.show()